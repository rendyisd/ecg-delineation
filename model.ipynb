{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "import util_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = util_func.open_pickle('data/ludb_processed/ludb.pickle')\n",
    "\n",
    "features = data['features']\n",
    "y = np.array(data['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting to train, validation, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_temp, y_train, y_temp = train_test_split(features, y, test_size=.2, shuffle=False, random_state=2023)\n",
    "features_test, features_val, y_test, y_val = train_test_split(features_temp, y_temp, test_size=.5, shuffle=False, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "zpad_length_train = []\n",
    "\n",
    "for row in features_train:\n",
    "    X_train.append(row[0])\n",
    "    zpad_length_train.append(row[1])\n",
    "\n",
    "X_val = []\n",
    "zpad_length_val = []\n",
    "\n",
    "for row in features_val:\n",
    "    X_val.append(row[0])\n",
    "    zpad_length_val.append(row[1])\n",
    "\n",
    "X_test = []\n",
    "zpad_length_test = []\n",
    "\n",
    "for row in features_test:\n",
    "    X_test.append(row[0])\n",
    "    zpad_length_test.append(row[1])\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n",
    "# Reshape X to be the same format as y\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    'Zero padding',\n",
    "    'Pon-Poff',\n",
    "    'Poff-QRSon',\n",
    "    'QRSon-Rpeak',\n",
    "    'Rpeak-QRSoff',\n",
    "    'QRSoff-Ton',\n",
    "    'Ton-Toff',\n",
    "    'Toff-Pon2'\n",
    "]\n",
    "COLORS = { # Zero padding given no color\n",
    "    1: 'red',\n",
    "    2: 'darkorange',\n",
    "    3: 'yellow',\n",
    "    4: 'green',\n",
    "    5: 'blue',\n",
    "    6: 'darkcyan',\n",
    "    7: 'purple'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(input_shape, output, lr=1e-5, n_layer=1):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    # Conv layers\n",
    "    model.add(tf.keras.layers.Conv1D(8, 3, input_shape=input_shape, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv1D(16, 3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv1D(64, 3, padding='same', activation='relu'))\n",
    "\n",
    "    # Bidirectional LSTM\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, input_shape=input_shape, return_sequences=True)))\n",
    "\n",
    "    for i in range(n_layer-1):\n",
    "        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, return_sequences=True)))\n",
    "\n",
    "    # Fully connected layers\n",
    "    model.add(tf.keras.layers.Dense(output, activation='softmax'))\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training and validation accuracy\n",
    "def plot_acc_loss(model_h, model_name):\n",
    "    model_res_path = f'result/{model_name}'\n",
    "    util_func.make_dir(model_res_path)\n",
    "\n",
    "    train_acc = model_h.history['accuracy']\n",
    "    train_loss = model_h.history['loss']\n",
    "\n",
    "    val_acc = model_h.history['val_accuracy']\n",
    "    val_loss = model_h.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_acc, label='Train Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting training and validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_loss, label='Train Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_res_path}/Train_val_acc_loss.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes is a list that contains class names in string\n",
    "def calc_metrics(y_true, y_pred, model_name):\n",
    "    model_res_path = f'result/{model_name}'\n",
    "    util_func.make_dir(model_res_path)\n",
    "\n",
    "    y_true = y_true.reshape(y_true.shape[0] * y_true.shape[1], y_true.shape[2])\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0] * y_pred.shape[1], y_pred.shape[2])\n",
    "\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        'Recall': [],\n",
    "        'Precision': [],\n",
    "        'Specificity': [],\n",
    "        'F1-score': [],\n",
    "        'Accuracy': [],\n",
    "        'Error rate': []\n",
    "    }\n",
    "    \n",
    "    sum_tp = 0\n",
    "    sum_fn = 0\n",
    "    sum_fp = 0\n",
    "    sum_tn = 0\n",
    "    \n",
    "    for i in range(len(cm)):\n",
    "        tp = cm[i, i]\n",
    "        fn = np.sum(cm[i, :]) - tp\n",
    "        fp = np.sum(cm[:, i]) - tp\n",
    "        tn = np.sum(cm) - (tp + fn + fp)\n",
    "\n",
    "        sum_tp += tp\n",
    "        sum_fn += fn\n",
    "        sum_fp += fp\n",
    "        sum_tn += tn\n",
    "\n",
    "        recall = tp / (tp + fn)\n",
    "        precision = tp / (tp + fp)\n",
    "        specificity = tn / (tn + fp)\n",
    "        f1 = 2 * (recall * precision) / (recall + precision)\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        error = (fp + fn) / (tp + tn + fp + fn)\n",
    "        \n",
    "        metrics['Recall'].append(recall)\n",
    "        metrics['Precision'].append(precision)\n",
    "        metrics['Specificity'].append(specificity)\n",
    "        metrics['F1-score'].append(f1)\n",
    "        metrics['Accuracy'].append(accuracy)\n",
    "        metrics['Error rate'].append(error)\n",
    "    \n",
    "    # Macro-averaged\n",
    "    metrics['Recall'].append( np.sum(metrics['Recall']) / len(CLASSES) )\n",
    "    metrics['Precision'].append( np.sum(metrics['Precision']) / len(CLASSES) )\n",
    "    metrics['Specificity'].append( np.sum(metrics['Specificity']) / len(CLASSES) )\n",
    "    metrics['F1-score'].append( np.sum(metrics['F1-score']) / len(CLASSES) )\n",
    "    metrics['Accuracy'].append( np.sum(metrics['Accuracy']) / len(CLASSES) )\n",
    "    metrics['Error rate'].append( np.sum(metrics['Error rate']) / len(CLASSES) )\n",
    "\n",
    "    # Micro-averaged\n",
    "    micro_recall = sum_tp / (sum_tp + sum_fn)\n",
    "    micro_precision = sum_tp / (sum_tp + sum_fp)\n",
    "    metrics['Recall'].append(micro_recall)\n",
    "    metrics['Precision'].append(micro_precision)\n",
    "    metrics['Specificity'].append(sum_tn / (sum_tn + sum_fp))\n",
    "    metrics['F1-score'].append(2 * (micro_recall * micro_precision) / (micro_recall + micro_precision))\n",
    "    metrics['Accuracy'].append( (sum_tp + sum_tn) / (sum_tp + sum_tn + sum_fp + sum_fn) )\n",
    "    metrics['Error rate'].append( (sum_fp + sum_fn) / (sum_tp + sum_tn + sum_fp + sum_fn) )\n",
    "\n",
    "    metrics_indexes = CLASSES + ['Macro-averaged', 'Micro-averaged']\n",
    "\n",
    "    metrics_dataframe = pd.DataFrame(metrics, index=metrics_indexes)\n",
    "    metrics_dataframe.to_csv(f'{model_res_path}/metrics.csv')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix Heatmap')\n",
    "    plt.savefig(f'{model_res_path}/CM.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_pr(y_true, y_pred, model_name):\n",
    "    model_res_path = f'result/{model_name}'\n",
    "    util_func.make_dir(model_res_path)\n",
    "\n",
    "    y_true = y_true.reshape(y_true.shape[0] * y_true.shape[1], y_true.shape[2])\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0] * y_pred.shape[1], y_pred.shape[2])\n",
    "    \n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    precision, recall, average_precision = {}, {}, {}\n",
    "\n",
    "    # exclude zero padding on first index\n",
    "    for i in range(1, 8):\n",
    "        yt_i = y_true[:, i]\n",
    "        yp_i = y_pred[:, i]\n",
    "        fpr[i], tpr[i], _ = roc_curve(yt_i, yp_i)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        precision[i], recall[i], _ = precision_recall_curve(yt_i, yp_i)\n",
    "        average_precision[i] = average_precision_score(yt_i, yp_i)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=150)\n",
    "\n",
    "    for i in range(1, 8):\n",
    "        plt.plot(\n",
    "            fpr[i],\n",
    "            tpr[i],\n",
    "            color=COLORS[i],\n",
    "            lw=2,\n",
    "            label=f'Class {CLASSES[i]} (AUC = {roc_auc[i]:.2f})'\n",
    "        )\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC Curve')\n",
    "    ax.legend(loc='lower right')\n",
    "    fig.savefig(f'{model_res_path}/ROC_curve.jpg', bbox_inches='tight')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=150)\n",
    "    for i in range(1, 8):\n",
    "        plt.plot(\n",
    "            recall[i],\n",
    "            precision[i],\n",
    "            color=COLORS[i],\n",
    "            lw=2,\n",
    "            label=f'Class {CLASSES[i]} (AP = {average_precision[i]:.2f})',\n",
    "        )\n",
    "\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title('Precision-Recall Curve')\n",
    "    ax.legend(loc='lower left')\n",
    "    fig.savefig(f'{model_res_path}/PR_curve.jpg', bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = generate_model((X_train.shape[1], 1), 8)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSES = [\n",
    "#     'Zero padding',\n",
    "#     'Pon-Poff',\n",
    "#     'Poff-QRSon',\n",
    "#     'QRSon-Rpeak',\n",
    "#     'Rpeak-QRSoff',\n",
    "#     'QRSoff-Ton',\n",
    "#     'Ton-Toff',\n",
    "#     'Toff-Pon2'\n",
    "# ]\n",
    "\n",
    "# plot_acc_loss(history)\n",
    "# calc_metrics(y_test, y_pred)\n",
    "# roc_pr(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_temp = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n",
    "# y_pred_temp = np.argmax(y_pred, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 42\n",
    "# signal_length = len(X_temp[i]) - zpad_length_test[i]\n",
    "# ECGSignal.plot_signal_segments(X_temp[i, 0:signal_length], y_pred_temp[i, 0:signal_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using CMA-ES (Covariance Matrix Adaptation - Evolution Strategy), implementation provided by optuna.<br>\n",
    "<br>\n",
    "CMA-ES objective will be to minimize validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = [8, 16, 32, 64]\n",
    "\n",
    "def objective(trial, X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    start_time = time.time()\n",
    "\n",
    "    lr = np.round(trial.suggest_float('lr', 1e-5, 1e-1, log=True), decimals=5)\n",
    "    n_layer = trial.suggest_int('n_layer', 1, 5)\n",
    "    batch_size_index = trial.suggest_int('batch_size_index', 0, len(BATCH_SIZES)-1)\n",
    "    bs = BATCH_SIZES[batch_size_index]\n",
    "\n",
    "    model_name = f'ConvBiLSTM-LR_{lr}-Nlayer_{n_layer}-BS_{bs}'\n",
    "    model = generate_model((X_train.shape[1], 1), 8, lr=lr, n_layer=n_layer)\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=bs, validation_data=(X_val, y_val))\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    plot_acc_loss(history, model_name)\n",
    "    calc_metrics(y_test, y_pred, model_name)\n",
    "    roc_pr(y_test, y_pred, model_name)\n",
    "\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_elapsed = end_time - start_time\n",
    "\n",
    "    with open(f'result/{model_name}/Model_info.txt', 'w') as info_file:\n",
    "        info_file.write(f'{model_name}\\n')\n",
    "        info_file.write(f'Learning Rate: {lr} | n_layer: {n_layer} | Batch Size: {bs}\\n')\n",
    "        info_file.write(f'Elapsed Time: {time_elapsed:.2f} seconds\\n')\n",
    "\n",
    "    return np.min(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_wrapper = partial(\n",
    "    objective,\n",
    "    X_train=X_train,X_val=X_val, X_test=X_test,\n",
    "    y_train=y_train, y_val=y_val, y_test=y_test\n",
    ")\n",
    "sampler = optuna.samplers.CmaEsSampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='minimize')\n",
    "study.optimize(objective_wrapper, n_trials=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
