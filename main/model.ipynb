{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "# from functools import partial\n",
    "\n",
    "# import optuna\n",
    "\n",
    "import confmain\n",
    "from util_module import util_func\n",
    "from util_module import model_func\n",
    "from util_module.ecg_signal import ECGSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = util_func.open_pickle('../data/ludb_processed/ludb_i_ii_iii.pickle')\n",
    "\n",
    "features = data['features']\n",
    "y = np.array(data['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting to train, validation, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_val, features_test, y_train, y_val, y_test = model_func.train_val_test_split(features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, zpad_length_train, zpad_length_val, zpad_length_test = model_func.get_x(features_train, features_val, features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using CMA-ES (Covariance Matrix Adaptation - Evolution Strategy), implementation provided by optuna.<br>\n",
    "<br>\n",
    "CMA-ES objective will be to minimize validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_segments(X, y, zpad, idx, save_path):\n",
    "    signal = X[idx].flatten()\n",
    "    segment_map = y[idx].argmax(axis=1)\n",
    "\n",
    "    beat_span = len(signal) - zpad[idx]\n",
    "\n",
    "    signal = signal[:beat_span]\n",
    "    segment_map = segment_map[:beat_span]\n",
    "\n",
    "    ECGSignal.plot_signal_segments(signal, segment_map, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = [8, 16, 32, 64]\n",
    "\n",
    "# def objective(trial, X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "# # def objective(trial):\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     lr = np.round(trial.suggest_float('lr', 1e-5, 1e-3, log=True), decimals=5)\n",
    "#     n_layer = trial.suggest_int('n_layer', 1, 5)\n",
    "#     batch_size_index = trial.suggest_int('batch_size_index', 0, len(BATCH_SIZES)-1)\n",
    "#     bs = BATCH_SIZES[batch_size_index]\n",
    "\n",
    "#     model_name = f'ConvBiLSTM-LR_{lr}-Nlayer_{n_layer}-BS_{bs}'\n",
    "#     result_path = f'../result/{model_name}'\n",
    "\n",
    "#     model = model_func.generate_model((X_train.shape[1], 1), 8, lr=lr, n_layer=n_layer)\n",
    "#     history = model.fit(X_train, y_train, epochs=200, batch_size=bs, validation_data=(X_val, y_val))\n",
    "\n",
    "#     model_func.plot_acc_loss(history, result_path)\n",
    "\n",
    "#     # PREDICT TRAIN\n",
    "#     save_to_train = f'{result_path}/train'\n",
    "#     y_pred_train = model.predict(X_train)\n",
    "#     model_func.calc_metrics(y_train, y_pred_train, save_to_train)\n",
    "#     model_func.roc_pr(y_train, y_pred_train, save_to_train)\n",
    "    \n",
    "#     util_func.make_dir(f'{save_to_train}/delineation')\n",
    "#     plot_segments(X_train, y_train, zpad=zpad_length_train, idx=0, save_path=f'{save_to_train}/delineation/Expert_annotated.jpg') # Expert annotated\n",
    "#     plot_segments(X_train, y_pred_train, zpad=zpad_length_train, idx=0, save_path=f'{save_to_train}/delineation/Prediction.jpg') # Prediction\n",
    "#     # ====================================================\n",
    "\n",
    "#     # PREDICT VALIDATION\n",
    "#     save_to_val = f'{result_path}/val'\n",
    "#     y_pred_val = model.predict(X_val)\n",
    "#     model_func.calc_metrics(y_val, y_pred_val, save_to_val)\n",
    "#     model_func.roc_pr(y_val, y_pred_val, save_to_val)\n",
    "\n",
    "#     util_func.make_dir(f'{save_to_val}/delineation')\n",
    "#     plot_segments(X_val, y_val, zpad=zpad_length_val, idx=0, save_path=f'{save_to_val}/delineation/Expert_annotated.jpg') # Expert annotated\n",
    "#     plot_segments(X_val, y_pred_val, zpad=zpad_length_val, idx=0, save_path=f'{save_to_val}/delineation/Prediction.jpg') # Prediction\n",
    "#     # ====================================================\n",
    "\n",
    "#     # PREDICT test\n",
    "#     save_to_test = f'{result_path}/test'\n",
    "#     y_pred_test = model.predict(X_test)\n",
    "#     model_func.calc_metrics(y_test, y_pred_test, save_to_test)\n",
    "#     model_func.roc_pr(y_test, y_pred_test, save_to_test)\n",
    "\n",
    "#     util_func.make_dir(f'{save_to_test}/delineation')\n",
    "#     plot_segments(X_test, y_test, zpad=zpad_length_test, idx=0, save_path=f'{save_to_test}/delineation/Expert_annotated.jpg') # Expert annotated\n",
    "#     plot_segments(X_test, y_pred_test, zpad=zpad_length_test, idx=0, save_path=f'{save_to_test}/delineation/Prediction.jpg') # Prediction\n",
    "#     # ====================================================\n",
    "\n",
    "#     val_loss = history.history['val_loss'][-1]\n",
    "#     if np.isnan(val_loss):\n",
    "#         val_loss_score = 1 # High enough to not be picked\n",
    "#     else:\n",
    "#         val_loss_score = val_loss\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     time_elapsed = end_time - start_time\n",
    "#     with open(f'{result_path}/Model_info.txt', 'w') as info_file:\n",
    "#         info_file.write(f'{model_name} | Last epoch val loss: {val_loss_score}\\n')\n",
    "#         info_file.write(f'Learning Rate: {lr} | n_layer: {n_layer} | Batch Size: {bs}\\n')\n",
    "#         info_file.write(f'Time elapsed: {time_elapsed:.2f} seconds\\n')\n",
    "\n",
    "#     return val_loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective_wrapper = partial(\n",
    "#     objective,\n",
    "#     X_train=X_train,X_val=X_val, X_test=X_test,\n",
    "#     y_train=y_train, y_val=y_val, y_test=y_test\n",
    "# )\n",
    "# sampler = optuna.samplers.CmaEsSampler()\n",
    "# study = optuna.create_study(study_name='cma-es', sampler=sampler, direction='minimize')\n",
    "# study.optimize(objective_wrapper, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(X_train, X_val, X_test, y_train, y_val, y_test, lead):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Good fit model architecture\n",
    "    lr = 0\n",
    "    n_layer = 0\n",
    "    bs = 0\n",
    "    epoch = 0\n",
    "\n",
    "    model_name = f'ConvBiLSTM--{lead}--LR_{lr}-Nlayer_{n_layer}-BS_{bs}-Epoch_{epoch}'\n",
    "    result_path = f'../result/{model_name}'\n",
    "    save_to_train = f'{result_path}/train'\n",
    "    save_to_val = f'{result_path}/val'\n",
    "    save_to_test = f'{result_path}/test'\n",
    "\n",
    "    util_func.make_dir(f'{save_to_train}/delineation')\n",
    "    util_func.make_dir(f'{save_to_val}/delineation')\n",
    "    util_func.make_dir(f'{save_to_test}/delineation')\n",
    "\n",
    "\n",
    "    model = model_func.generate_model((X_train.shape[1], 1), 8, lr=lr, n_layer=n_layer)\n",
    "    history = model.fit(X_train, y_train, epochs=epoch, batch_size=bs, validation_data=(X_val, y_val))\n",
    "\n",
    "    model.save(f'{model_name}.h5')\n",
    "    model_func.plot_acc_loss(history, result_path)\n",
    "\n",
    "    # PREDICT TRAIN\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    model_func.calc_metrics(y_train, y_pred_train, save_to_train)\n",
    "    model_func.roc_pr(y_train, y_pred_train, save_to_train)\n",
    "    \n",
    "    for i in range(0, 41, 10):\n",
    "        plot_segments(X_train, y_train, zpad=zpad_length_train, idx=i, save_path=f'{save_to_train}/delineation/Expert_annotated_{i}.jpg') # Expert annotated\n",
    "        plot_segments(X_train, y_pred_train, zpad=zpad_length_train, idx=i, save_path=f'{save_to_train}/delineation/Prediction_{i}.jpg') # Prediction\n",
    "    # ====================================================\n",
    "\n",
    "    # PREDICT VALIDATION\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    model_func.calc_metrics(y_val, y_pred_val, save_to_val)\n",
    "    model_func.roc_pr(y_val, y_pred_val, save_to_val)\n",
    "\n",
    "    for i in range(0, 41, 10):\n",
    "        plot_segments(X_val, y_val, zpad=zpad_length_val, idx=i, save_path=f'{save_to_val}/delineation/Expert_annotated_{i}.jpg') # Expert annotated\n",
    "        plot_segments(X_val, y_pred_val, zpad=zpad_length_val, idx=i, save_path=f'{save_to_val}/delineation/Prediction_{i}.jpg') # Prediction\n",
    "    # ====================================================\n",
    "\n",
    "    # PREDICT test\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    model_func.calc_metrics(y_test, y_pred_test, save_to_test)\n",
    "    model_func.roc_pr(y_test, y_pred_test, save_to_test)\n",
    "\n",
    "    for i in range(0, 41, 10):\n",
    "        plot_segments(X_test, y_test, zpad=zpad_length_test, idx=i, save_path=f'{save_to_test}/delineation/Expert_annotated_{i}.jpg') # Expert annotated\n",
    "        plot_segments(X_test, y_pred_test, zpad=zpad_length_test, idx=i, save_path=f'{save_to_test}/delineation/Prediction_{i}.jpg') # Prediction\n",
    "    # ====================================================\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_elapsed = end_time - start_time\n",
    "    with open(f'{result_path}/Model_info.txt', 'w') as info_file:\n",
    "        info_file.write(f'{model_name}\\n')\n",
    "        info_file.write(f'Learning Rate: {lr} | n_layer: {n_layer} | Batch Size: {bs}\\n | Epoch: {epoch}')\n",
    "        info_file.write(f'Time elapsed: {time_elapsed:.2f} seconds\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_results(X_train, X_val, X_test, y_train, y_val, y_test, lead='i_ii_iii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = util_func.open_pickle('../data/ludb_processed/ludb_i.pickle')\n",
    "\n",
    "# features = data['features']\n",
    "# y = np.array(data['labels'])\n",
    "\n",
    "# features_train, features_val, features_test, y_train, y_val, y_test = model_func.train_val_test_split(features, y)\n",
    "\n",
    "# X_train, X_val, X_test, zpad_length_train, zpad_length_val, zpad_length_test = model_func.get_x(features_train, features_val, features_test)\n",
    "\n",
    "# generate_results(X_train, X_val, X_test, y_train, y_val, y_test, lead='i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = util_func.open_pickle('../data/ludb_processed/ludb_ii.pickle')\n",
    "\n",
    "# features = data['features']\n",
    "# y = np.array(data['labels'])\n",
    "\n",
    "# features_train, features_val, features_test, y_train, y_val, y_test = model_func.train_val_test_split(features, y)\n",
    "\n",
    "# X_train, X_val, X_test, zpad_length_train, zpad_length_val, zpad_length_test = model_func.get_x(features_train, features_val, features_test)\n",
    "\n",
    "# generate_results(X_train, X_val, X_test, y_train, y_val, y_test, lead='ii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = util_func.open_pickle('../data/ludb_processed/ludb_iii.pickle')\n",
    "\n",
    "# features = data['features']\n",
    "# y = np.array(data['labels'])\n",
    "\n",
    "# features_train, features_val, features_test, y_train, y_val, y_test = model_func.train_val_test_split(features, y)\n",
    "\n",
    "# X_train, X_val, X_test, zpad_length_train, zpad_length_val, zpad_length_test = model_func.get_x(features_train, features_val, features_test)\n",
    "\n",
    "# generate_results(X_train, X_val, X_test, y_train, y_val, y_test, lead='iii')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
