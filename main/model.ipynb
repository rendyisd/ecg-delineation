{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import confmain\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "\n",
    "from util_module import util_func\n",
    "from util_module import model_func\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load X and Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, val_set, test_set, zpad_length = util_func.get_x_y('../data/ludb_processed/ludb_ii.pickle')\n",
    "\n",
    "# X_train, y_train = train_set\n",
    "# X_val, y_val = val_set\n",
    "# X_test, y_test = test_set\n",
    "\n",
    "# zpad_length_train, zpad_length_val, zpad_length_test = zpad_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, val_set, test_set, zpad_length = util_func.get_x_y(f'../data/ludb_processed/ludb_{lead}.pickle')\n",
    "\n",
    "# X_train = util_func.open_pickle(f'../data/temp/{lead}/X_train')\n",
    "# X_val = util_func.open_pickle(f'../data/temp/{lead}/X_val')\n",
    "# X_test = util_func.open_pickle(f'../data/temp/{lead}/X_test')\n",
    "# y_train = util_func.open_pickle(f'../data/temp/{lead}/y_train')\n",
    "# y_val = util_func.open_pickle(f'../data/temp/{lead}/y_val')\n",
    "# y_test = util_func.open_pickle(f'../data/temp/{lead}/y_test')\n",
    "# train_set = X_train, y_train\n",
    "# val_set = X_val, y_val\n",
    "# test_set = X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Transfer Learning Model Hafizh**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_training_wrapper(lead, model_info):\n",
    "#     train_set, val_set, test_set, zpad_length = util_func.get_x_y(f'../data/ludb_processed/ludb_{lead}.pickle')\n",
    "\n",
    "#     # X_train = util_func.open_pickle(f'../data/temp/{lead}/X_train')\n",
    "#     # X_val = util_func.open_pickle(f'../data/temp/{lead}/X_val')\n",
    "#     # X_test = util_func.open_pickle(f'../data/temp/{lead}/X_test')\n",
    "#     # y_train = util_func.open_pickle(f'../data/temp/{lead}/y_train')\n",
    "#     # y_val = util_func.open_pickle(f'../data/temp/{lead}/y_val')\n",
    "#     # y_test = util_func.open_pickle(f'../data/temp/{lead}/y_test')\n",
    "#     # train_set = X_train, y_train\n",
    "#     # val_set = X_val, y_val\n",
    "#     # test_set = X_test, y_test\n",
    "\n",
    "#     X_train, y_train = train_set\n",
    "#     X_val, y_val = val_set\n",
    "#     X_test, y_test = test_set\n",
    "\n",
    "#     zpad_length_train, zpad_length_val, zpad_length_test = zpad_length\n",
    "\n",
    "#     model_hafizh = tf.keras.models.load_model(f'../model/base_model/hafizh.h5')\n",
    "\n",
    "#     pretrained_layers = model_hafizh.layers[1:-2]\n",
    "\n",
    "#     for layer in pretrained_layers:\n",
    "#         layer.trainable = False\n",
    "\n",
    "#     input_layer = tf.keras.layers.Input(shape=(816, 1))\n",
    "#     x = tf.keras.layers.Conv1D(8, 3, padding='same')(input_layer)\n",
    "#     x = tf.keras.layers.LayerNormalization()(x)\n",
    "#     x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "#     for layer in pretrained_layers:\n",
    "#         x = layer(x)\n",
    "    \n",
    "#     x = tf.keras.layers.Dropout(0.3)(x)\n",
    "#     x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(816, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(1e-4)))(x)\n",
    "#     x = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "#     x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "#     output_layer = tf.keras.layers.Dense(8, activation='softmax')(x)\n",
    "\n",
    "#     new_model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "#     new_model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-3), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     initial_epochs = 100\n",
    "#     history_phase_1 = new_model.fit(X_train, y_train, epochs=initial_epochs, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "#     # Fine-tune\n",
    "#     for layer in pretrained_layers[-4:]:\n",
    "#         layer.trainable = True\n",
    "#     new_model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-5), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#     fine_tune_epochs = 200\n",
    "#     total_epochs = initial_epochs + fine_tune_epochs\n",
    "#     history_phase_2 = new_model.fit(X_train, y_train, epochs=total_epochs, batch_size=32, initial_epoch=history_phase_1.epoch[-1], validation_data=(X_val, y_val))\n",
    "\n",
    "#     stop_time = time.time()\n",
    "\n",
    "#     history_combined = {}\n",
    "#     for key in history_phase_1.history.keys():\n",
    "#         history_combined[key] = history_phase_1.history[key] + history_phase_2.history[key]\n",
    "\n",
    "#     model_info['Time elapsed'] = stop_time - start_time\n",
    "\n",
    "#     model_func.generate_results(new_model, history_combined, model_info, train_set, val_set, test_set, zpad_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Hafizh Modified (Without Transfer Learning)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hafizh_modified():\n",
    "    input_layer = tf.keras.layers.Input(shape=(816, 1))\n",
    "    x = tf.keras.layers.Conv1D(8, 3, padding='same')(input_layer)\n",
    "    # x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(16, 3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv1D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv1D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv1D(256, 3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv1D(512, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "    # x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(816, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(1e-4)))(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "    # x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    output_layer = tf.keras.layers.Dense(8, activation='softmax')(x)\n",
    "\n",
    "    new_model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    new_model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-3), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jordan - Complex Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_complex_model(input_shape, output, lr=1e-3, n_layer=1):\n",
    "    # optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "\n",
    "    input_layer = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(8, 5, padding=\"same\")(input_layer)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(16, 5, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(32, 5, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(64, 5, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(128, 5, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(\n",
    "        256, 7, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(1e-4)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(\n",
    "        512, 7, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(1e-4)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    for _ in range(n_layer):\n",
    "        x = tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.LSTM(\n",
    "                input_shape[0],\n",
    "                return_sequences=True,\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "            )\n",
    "        )(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    output_layer = tf.keras.layers.Dense(\n",
    "        output, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(1e-4)\n",
    "    )(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_wrapper(lead, model_info):\n",
    "    train_set, val_set, test_set, zpad_length = util_func.get_x_y(f'../data/ludb_processed/ludb_{lead}.pickle')\n",
    "\n",
    "    # X_train = util_func.open_pickle(f'../data/temp/{lead}/X_train')\n",
    "    # X_val = util_func.open_pickle(f'../data/temp/{lead}/X_val')\n",
    "    # X_test = util_func.open_pickle(f'../data/temp/{lead}/X_test')\n",
    "    # y_train = util_func.open_pickle(f'../data/temp/{lead}/y_train')\n",
    "    # y_val = util_func.open_pickle(f'../data/temp/{lead}/y_val')\n",
    "    # y_test = util_func.open_pickle(f'../data/temp/{lead}/y_test')\n",
    "    # train_set = X_train, y_train\n",
    "    # val_set = X_val, y_val\n",
    "    # test_set = X_test, y_test\n",
    "\n",
    "    X_train, y_train = train_set\n",
    "    X_val, y_val = val_set\n",
    "    X_test, y_test = test_set\n",
    "\n",
    "    model = generate_complex_model((816, 1), 8, lr=0.00026, n_layer=3)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=300, batch_size=32, validation_data=(X_val, y_val))\n",
    "    stop_time = time.time()\n",
    "\n",
    "    model_info['Time elapsed'] = stop_time - start_time\n",
    "\n",
    "    model_func.generate_results(model, history.history, model_info, train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEADS = ['i', 'ii', 'iii', 'avr', 'avl', 'avf', 'v1', 'v2', 'v3', 'v4', 'v5', 'v6']\n",
    "LEADS = ['avf']\n",
    "\n",
    "for lead in LEADS:\n",
    "    model_info = {\n",
    "        'name': f'{lead}-BayesianProposed',\n",
    "        'lead': lead,\n",
    "        'batch_size': 32,\n",
    "        'epochs': 300,\n",
    "        'n_layer': 3,\n",
    "        'optimizer': 'RMSprop(lr=0.00026)',\n",
    "        'additional info': ''\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        model_training_wrapper(lead, model_info)\n",
    "    \n",
    "    except:\n",
    "        print(f'Lead-{lead} failed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
